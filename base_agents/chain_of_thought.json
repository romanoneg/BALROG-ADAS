{
    "code": "import copy\nimport re\n\nfrom balrog.agents.base import BaseAgent\nfrom balrog.client import LLMClientWrapper\n\n\nclass ChainOfThoughtAgent(BaseAgent):\n    \"\"\"An agent that performs actions using a chain-of-thought reasoning process.\"\"\"\n\n    def __init__(self, client_factory: LLMClientWrapper, prompt_builder, config):\n        \"\"\"Initialize the ChainOfThoughtAgent with a client, prompt builder, and configuration.\n\n        Args:\n            client_factory (LLMClientWrapper): A factory for creating the LLM client instance.\n            prompt_builder (PromptBuilder): Object to build prompts for the agent.\n            config: Configuration object containing settings for the agent.\n        \"\"\"\n        super().__init__(client_factory, prompt_builder)\n        self.remember_cot = config.agent.remember_cot\n\n    def act(self, obs, prev_action=None):\n        \"\"\"Generate the next action using chain-of-thought reasoning based on the current observation.\n\n        Args:\n            obs (dict): The current observation in the environment.\n            prev_action (str, optional): The previous action taken.\n\n        Returns:\n            LLMResponse: The response containing the final selected action.\n        \"\"\"\n        if prev_action:\n            self.prompt_builder.update_action(prev_action)\n\n        self.prompt_builder.update_observation(obs)\n\n        messages = self.prompt_builder.get_prompt()\n\n        # Add CoT-specific instructions to the prompt\n        cot_instructions = \"\"\"\nFirst think about what's the best course of action step by step.\nFinally, provide a single output action at the end of the message in the form of: ACTION: <action>\n        \"\"\".strip()\n\n        messages[-1].content += \"\\n\\n\" + cot_instructions\n\n        # Generate the CoT reasoning\n        cot_reasoning = self.client.generate(messages)\n\n        # Extract the final answer from the CoT reasoning\n        final_answer = self._extract_final_answer(cot_reasoning)\n\n        return final_answer\n\n    def _extract_final_answer(self, reasoning):\n        \"\"\"Extract the final action from the chain-of-thought reasoning response.\n\n        Args:\n            reasoning (LLMResponse): The response containing CoT reasoning and action.\n\n        Returns:\n            LLMResponse: The response with the extracted final action.\n        \"\"\"\n\n        def filter_letters(input_string):\n            return re.sub(r\"[^a-zA-Z\\s:]\", \"\", input_string)\n\n        answer = copy.deepcopy(reasoning)\n        self.prompt_builder.update_reasoning(reasoning.completion)\n        answer = answer._replace(reasoning=answer.completion)\n        answer = answer._replace(completion=filter_letters(answer.completion).split(\"ACTION:\")[-1].strip())\n\n        return answer\n"
}